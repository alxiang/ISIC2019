{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1802.09088.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import Concatenate, Lambda # batch discrimination\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skimage.measure\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build One-Class GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_common_layers(y, set_alpha=0.3):\n",
    "    #y = BatchNormalization(momentum=0.8)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    #y = Dropout(0.25)(y)\n",
    "    y = LeakyReLU(alpha=set_alpha)(y)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"/Users/alecx/Downloads/AWS-LESIONDATA-2019_v2.npz\")\n",
    "\n",
    "X_train = data[\"imageList\"]\n",
    "y_train = data[\"targetList\"]\n",
    "imageValList = data[\"imageValList\"]\n",
    "targetValList = data[\"targetValList\"]\n",
    "testList = data[\"testList\"]\n",
    "targetTestList = data[\"targetTestList\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCC():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 32\n",
    "        self.img_cols = 32\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = 3\n",
    "        self.latent_dim = 128\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "        losses = ['binary_crossentropy']\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=losses,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input\n",
    "        # and generates the image\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator([noise])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model([noise], [valid])\n",
    "        self.combined.compile(loss=losses,\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "\n",
    "        i = Reshape((1, 1, 128), input_shape=(128,))(noise)\n",
    "        \n",
    "        i = Conv2DTranspose(128, kernel_size=4, padding=\"valid\")(i)\n",
    "        i = add_common_layers(i)\n",
    "        \n",
    "        i = UpSampling2D(size=(2, 2))(i)\n",
    "        i = Conv2D(64, kernel_size=3, strides=1, padding=\"same\")(i)\n",
    "        i = add_common_layers(i, set_alpha=0)\n",
    "        \n",
    "        i = UpSampling2D(size=(2, 2))(i)\n",
    "        i = Conv2D(32, kernel_size=3, strides=1, padding=\"same\")(i)\n",
    "        i = add_common_layers(i, set_alpha=0)\n",
    "        \n",
    "        i = UpSampling2D(size=(2, 2))(i)\n",
    "        i = Conv2D(16, kernel_size=3, strides=1, padding=\"same\")(i)\n",
    "        i = add_common_layers(i, set_alpha=0)\n",
    "        \n",
    "        i = Conv2D(3, kernel_size=3, strides=1, padding=\"same\")(i)\n",
    "        #i = LeakyReLU(alpha=0)(i)\n",
    "\n",
    "        img = Activation(\"tanh\")(i)\n",
    "        \n",
    "        \n",
    "        model = Model([noise], img)\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        # batch_diversity = batch discrimination\n",
    "        img = Input(shape=self.img_shape)\n",
    "\n",
    "        i = Conv2D(16, kernel_size=3, strides=1, input_shape=(32,32,3), padding=\"same\")(img)\n",
    "        i = add_common_layers(i)\n",
    "        batch_div = Lambda(lambda x:K.mean(K.abs(x[:] - K.mean(x,axis=0)),axis=-1,keepdims=True))(i)\n",
    "        i = Concatenate()([i, batch_div])\n",
    "        \n",
    "        i = Conv2D(32, kernel_size=3, strides=2, padding=\"same\")(i)\n",
    "        i = add_common_layers(i)\n",
    "        batch_div = Lambda(lambda x:K.mean(K.abs(x[:] - K.mean(x,axis=0)),axis=-1,keepdims=True))(i)\n",
    "        i = Concatenate()([i, batch_div])\n",
    "        \n",
    "        i = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(i)\n",
    "        i = add_common_layers(i)\n",
    "        batch_div = Lambda(lambda x:K.mean(K.abs(x[:] - K.mean(x,axis=0)),axis=-1,keepdims=True))(i)\n",
    "        i = Concatenate()([i, batch_div])\n",
    "        \n",
    "        i = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(i)\n",
    "        #i = LeakyReLU(alpha=0.2)(i)\n",
    "        #i = Dropout(0.25)(i)\n",
    "\n",
    "        i = Flatten()(i)\n",
    "        \n",
    "        # Determine validity of the image\n",
    "        validity = Dense(1, activation=\"sigmoid\")(i)\n",
    "        \n",
    "        model = Model(img, [validity])\n",
    "        model.summary()  \n",
    "\n",
    "    \n",
    "        return model\n",
    "\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        data = np.load(\"/Users/alecx/Downloads/AWS-LESIONDATA-2019_v2.npz\")\n",
    "\n",
    "        X_train = data[\"imageList\"]\n",
    "        y_train = data[\"targetList\"]\n",
    "        imageValList = data[\"imageValList\"]\n",
    "        targetValList = data[\"targetValList\"]\n",
    "        testList = data[\"testList\"]\n",
    "        targetTestList = data[\"targetTestList\"]\n",
    "\n",
    "        # Configure inputs\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # Resize X_train from 224x224 to 32x32\n",
    "        # with average pooling from skimage blockreduce\n",
    "\n",
    "        X_train_small = np.empty((7133, 32, 32, 3))\n",
    "        for i in range(X_train_small.shape[0]):\n",
    "            X_train_small[i] = resize(X_train[i], output_shape=(32, 32, 3))\n",
    "    \n",
    "        X_train = X_train_small\n",
    "        \n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict([noise])\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, [valid])\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, [fake])\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch([noise], [valid])\n",
    "\n",
    "            # Plot the progress\n",
    "            print (epoch, d_loss, g_loss)\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                #self.save_model(epoch)\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 10, 3\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c, figsize=(10,30))\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt,:,:,:])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "    def save_model(self, epoch):\n",
    "\n",
    "        def save(model, model_name, epoch):\n",
    "            model_path = \"saved_model/%s_%d.json\" % (model_name, epoch)\n",
    "            weights_path = \"saved_model/%s_weights_%d.hdf5\" % (model_name, epoch)\n",
    "            options = {\"file_arch\": model_path,\n",
    "                        \"file_weight\": weights_path}\n",
    "            json_string = model.to_json()\n",
    "            open(options['file_arch'], 'w').write(json_string)\n",
    "            model.save_weights(options['file_weight'])\n",
    "\n",
    "        save(self.generator, \"generator\", epoch)\n",
    "        save(self.discriminator, \"discriminator\", epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 32, 32, 16)   448         input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 32, 32, 16)   64          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 32, 32, 1)    0           leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 32, 32, 17)   0           leaky_re_lu_46[0][0]             \n",
      "                                                                 lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 32)   4928        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 32)   128         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, 16, 16, 32)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 16, 16, 1)    0           leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 33)   0           leaky_re_lu_47[0][0]             \n",
      "                                                                 lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 64)     19072       concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 8, 64)     256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, 8, 8, 64)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 8, 8, 1)      0           leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 8, 8, 65)     0           leaky_re_lu_48[0][0]             \n",
      "                                                                 lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 4, 4, 128)    75008       concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 2048)         0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            2049        flatten_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 101,953\n",
      "Trainable params: 101,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 4, 4, 128)         262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 8, 8, 64)          73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_20 (UpSampling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 16, 16, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_21 (UpSampling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 32, 32, 16)        4624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)   (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 32, 32, 3)         435       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 360,547\n",
      "Trainable params: 360,067\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecx/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/Users/alecx/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.9212393 0.359375 ] 0.6719533\n",
      "1 [0.68224585 0.65625   ] 0.8296698\n",
      "2 [0.61113024 0.6640625 ] 0.96828926\n",
      "3 [0.5218483 0.78125  ] 1.179438\n",
      "4 [0.45566744 0.859375  ] 1.3091862\n",
      "5 [0.43140233 0.8515625 ] 1.31672\n",
      "6 [0.36857897 0.921875  ] 1.5564983\n",
      "7 [0.3866384 0.875    ] 1.3892317\n",
      "8 [0.3432604 0.8984375] 1.4150665\n",
      "9 [0.3878529 0.8828125] 1.420162\n",
      "10 [0.34411582 0.890625  ] 1.5858313\n",
      "11 [0.3701056 0.890625 ] 1.4807813\n",
      "12 [0.41221732 0.859375  ] 1.6644444\n",
      "13 [0.3466434 0.8671875] 1.5556135\n",
      "14 [0.38239533 0.8828125 ] 1.6251826\n",
      "15 [0.3296238 0.921875 ] 1.5792263\n",
      "16 [0.332711  0.9140625] 1.5656238\n",
      "17 [0.31870067 0.921875  ] 1.548876\n",
      "18 [0.23804212 0.96875   ] 1.5868287\n",
      "19 [0.2875631 0.953125 ] 1.4047683\n",
      "20 [0.35725984 0.8984375 ] 1.1994662\n",
      "21 [0.27530676 0.921875  ] 1.2269994\n",
      "22 [0.307367 0.921875] 1.0449368\n",
      "23 [0.20231041 0.9609375 ] 1.0767581\n",
      "24 [0.2525626 0.921875 ] 0.93676054\n",
      "25 [0.31510296 0.8984375 ] 0.8761375\n",
      "26 [0.25830448 0.9296875 ] 0.8306165\n",
      "27 [0.23616098 0.9375    ] 0.72782564\n",
      "28 [0.16630809 0.96875   ] 0.7514545\n",
      "29 [0.2293282 0.953125 ] 0.85080826\n",
      "30 [0.20633003 0.96875   ] 0.79566616\n",
      "31 [0.21278809 0.953125  ] 0.83752906\n",
      "32 [0.19519696 0.9765625 ] 0.7955367\n",
      "33 [0.18069583 0.9765625 ] 0.85825\n",
      "34 [0.22913378 0.9609375 ] 0.9300863\n",
      "35 [0.1726133 0.96875  ] 0.83262163\n",
      "36 [0.23657611 0.9453125 ] 0.88876975\n",
      "37 [0.18975079 0.9921875 ] 1.0357429\n",
      "38 [0.251836  0.9296875] 0.9691252\n",
      "39 [0.20809856 0.953125  ] 1.0958436\n",
      "40 [0.2256819 0.9453125] 1.1379062\n",
      "41 [0.25612915 0.9453125 ] 1.2097107\n",
      "42 [0.26255512 0.9609375 ] 1.2965448\n",
      "43 [0.28581023 0.90625   ] 1.2023693\n",
      "44 [0.19578579 0.9609375 ] 1.2715625\n",
      "45 [0.28508148 0.8984375 ] 1.4011562\n",
      "46 [0.21166413 0.9453125 ] 1.4308314\n",
      "47 [0.19159794 0.96875   ] 1.6467514\n",
      "48 [0.10098783 0.96875   ] 1.9639189\n",
      "49 [0.1067259 0.984375 ] 2.3830652\n",
      "50 [0.10322849 0.9765625 ] 2.412404\n",
      "51 [0.10629226 0.984375  ] 2.4690702\n",
      "52 [0.0838275 0.9921875] 2.621017\n",
      "53 [0.06048696 0.984375  ] 2.9355483\n",
      "54 [0.09423883 0.984375  ] 2.8280392\n",
      "55 [0.07829893 1.        ] 2.9504333\n",
      "56 [0.12667286 0.9765625 ] 2.9295318\n",
      "57 [0.13996318 0.9765625 ] 2.6613188\n",
      "58 [0.07132114 0.9921875 ] 2.37457\n",
      "59 [0.06772999 0.9921875 ] 2.4135711\n",
      "60 [0.11032727 0.96875   ] 2.440145\n",
      "61 [0.05598951 1.        ] 2.7201004\n",
      "62 [0.12769522 0.9765625 ] 2.7031069\n",
      "63 [0.17139271 0.9609375 ] 2.419184\n",
      "64 [0.05234567 1.        ] 2.6409633\n",
      "65 [0.18340194 0.9609375 ] 2.4493742\n",
      "66 [0.07204108 0.9921875 ] 2.2832837\n",
      "67 [0.066255 0.984375] 2.4507313\n",
      "68 [0.11612931 0.96875   ] 2.5372016\n",
      "69 [0.14081901 0.9609375 ] 2.6300526\n",
      "70 [0.08473379 0.984375  ] 2.7165818\n",
      "71 [0.11040056 0.9765625 ] 2.8568697\n",
      "72 [0.10407278 0.9765625 ] 3.1505558\n",
      "73 [0.09791233 0.984375  ] 3.1104689\n",
      "74 [0.08377588 0.984375  ] 2.8224778\n",
      "75 [0.16278282 0.9765625 ] 3.106809\n",
      "76 [0.15236753 0.9609375 ] 2.8307977\n",
      "77 [0.13688432 0.9765625 ] 2.9869752\n",
      "78 [0.07909091 0.9921875 ] 3.0118768\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-94f711235a6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mocc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOCC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mocc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-21f48ff5b883>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# Train the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;31m# Plot the progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "occ = OCC()\n",
    "occ.train(epochs=100000, batch_size=64, sample_interval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
